{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjeG46Gbjh2PJzF04rpmc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivaIg/Diabetes-classification/blob/main/diabetes_classification_shallow_learners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diabetes Prediction Challange with shallow learners**\n",
        "Task is to build a machine learning classifier that predicts whether a patient is diagnosed with diabetes or not, based on a set of health indicators.\n",
        "\n",
        "The dataset includes 21 features describing lifestyle, demographic, and health-related factors (e.g., BMI, smoking status, physical activity, age, blood pressure, cholesterol levels, etc.)."
      ],
      "metadata": {
        "id": "X7mmnKqICZ0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score,mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier,\n",
        "                              VotingClassifier, VotingRegressor, StackingClassifier,\n",
        "                              StackingRegressor)\n",
        "from sklearn.svm import SVR\n",
        "\n"
      ],
      "metadata": {
        "id": "W-1oyL-EoD_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the datasets"
      ],
      "metadata": {
        "id": "2PAAXYoaDi3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv')\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test.head()\n",
        "X_train.head()\n",
        "y_train.head()"
      ],
      "metadata": {
        "id": "qqP_qdmYpL3A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the data and perform one-hot encoding"
      ],
      "metadata": {
        "id": "Q9AVSBvHDtOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.drop(columns=[\"ID\"])\n",
        "y_train = y_train[\"Diabetes\"].map({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "id": "WDcBFqf4wuOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=['ID'], errors='ignore')\n",
        "X_test = X_test.drop(columns=['ID'], errors='ignore')"
      ],
      "metadata": {
        "id": "z3hL69VScrG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "oneHotEncodedColumn = enc.fit_transform(X_train[\"Gender\"].to_numpy().reshape(-1, 1))\n",
        "print(oneHotEncodedColumn[:25].toarray())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O4d9QlLgt-1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get feature names from encoder\n",
        "gender_encoded_df = pd.DataFrame(\n",
        "    oneHotEncodedColumn.toarray(),\n",
        "    columns=enc.get_feature_names_out([\"Gender\"]),\n",
        "    index=X_train.index  # Keep original index for alignment\n",
        ")\n",
        "\n",
        "# Drop original Gender column and concatenate encoded columns\n",
        "X = X_train.drop(\"Gender\", axis=1)\n",
        "X = pd.concat([X, gender_encoded_df], axis=1)\n"
      ],
      "metadata": {
        "id": "JO0lNiilu4qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split to test-train data sets\n",
        "\n"
      ],
      "metadata": {
        "id": "g4vn6Be9D16c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "yRjNisY5sIHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the best performance for benchmark"
      ],
      "metadata": {
        "id": "jCH_SQuMEDMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"SVC_rbf\": SVC(kernel= 'rbf',random_state=42),\n",
        "    \"SVC_poly\": SVC(kernel= 'poly',random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_split, y_train_split)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "w1wpCGyzbMXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing parameter tuning on base models"
      ],
      "metadata": {
        "id": "svJW04mkEn5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter tuning\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "model=LogisticRegression(random_state=42)\n",
        "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_yE7GQFKQ2Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "\n",
        "model=SVC(random_state=42,kernel='rbf')\n",
        "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "id": "jPOO2jL8S_QR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2, 3, 4]  # only for 'poly' kernel\n",
        "}\n",
        "\n",
        "\n",
        "model=SVC(random_state=42,kernel='poly')\n",
        "grid = RandomizedSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "id": "x1b5jhbc3cix",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "model=GradientBoostingClassifier(random_state=42)\n",
        "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vdgs10hcTQ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "model=RandomForestClassifier(random_state=42)\n",
        "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "id": "a0mDbTQXTZCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "\n",
        "model=DecisionTreeClassifier(random_state=42)\n",
        "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=1)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_split, y_train_split)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "grid_predictions = grid.predict(X_val)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_val, grid_predictions))"
      ],
      "metadata": {
        "id": "8uARex34Og0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing best parameter combinations with base models for best performance"
      ],
      "metadata": {
        "id": "zr-aVK3CE_tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42,C=0.1,penalty='l1',solver='liblinear'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42,class_weight= 'balanced', criterion= 'entropy', max_depth =10, max_features= None, min_samples_leaf= 1, min_samples_split= 2, splitter= 'random'),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42,bootstrap=False,max_depth=10,max_features='sqrt',n_estimators=300),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42,learning_rate=0.1,max_depth=5,max_features='sqrt',min_samples_leaf=1,min_samples_split=5,n_estimators=100,subsample=0.8),\n",
        "    \"SVC_rbf\": SVC(kernel= 'rbf',random_state=42,C=10,gamma='scale')\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_split, y_train_split)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kR1NnyeMxk3",
        "outputId": "ff9d2c7c-cde3-48fc-dece-dbabec88b2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.7448\n",
            "Decision Tree Accuracy: 0.7381\n",
            "Random Forest Accuracy: 0.7513\n",
            "Gradient Boosting Accuracy: 0.7525\n",
            "SVC_rbf Accuracy: 0.7507\n"
          ]
        }
      ]
    }
  ]
}